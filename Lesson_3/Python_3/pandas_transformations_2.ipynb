{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üêç.3 Pandas Data Transformations, Pt. 1 & Pt. 2!\n",
    "_Nate Robinson_\n",
    "\n",
    "~~Today's lesson will focus on understanding how we can use pandas to cut down on data manipulation workload and introduce some common methods for transforming data.~~\n",
    "\n",
    "Todays lesson will extend our Pandas transformations from Part 1. We'll be exploring a few more common data manipulation patterns and dicussing pythonic ways to handle some types of problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# We should append the custom module to our PYTHONPATH to have access\n",
    "# to the db_utils module!\n",
    "sys.path.append('../../custom')\n",
    "\n",
    "from db_utils import get_connection, validate_connection, get_data\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivating Question\n",
    "\n",
    "How can we manipulate data in `pandas` to to answer our questions?\n",
    "What are some common data manipulations steps we should feel comfortable with in pandas?\n",
    "There's more than one way to skin a cat! üôÄ\n",
    "\n",
    "We're going to be working with some **Milestone Updates** data which is somewhat messy but the only source for a lot of questions we'll need to solve.\n",
    "\n",
    "*Note: the column `update_lead_hours` here is a calculation of hours between when the update was made, and when the milestone occured. Negative means the milestone was created after it happened, postive means the milestone was created ahead of the actual event.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating login request with your identity provider. A browser window should have opened for you to complete the login. If you can't see it, check existing browser windows, or your OS settings. Press CTRL+C to abort and try again...\n"
     ]
    }
   ],
   "source": [
    "# We'll get started by establishing a database connection and pulling a predetermined dataset of milestone updates\n",
    "# We're selecting for only July 2020 and only arrival/departure milestones to ignore T&T events like last free day.\n",
    "conn, cur = get_connection()\n",
    "df = get_data('milestones.sql','file', conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions:\n",
    "\n",
    "We've got four questions ahead of us. The first two we'll do here:\n",
    "\n",
    "    1. What percentage of actual updates are human vs automated\n",
    "    2. What (if any) is the improvement in update speed earned by automation and operations teams\n",
    "    \n",
    "The latter two will be explored in Part 2 of this lesson:\n",
    "    \n",
    "    3. What milestones are frequently missing per given mode?\n",
    "    4. What are the fastest updates per mode\n",
    "    \n",
    "Keeping in mind for the above, we'll need to handle outliers and extraneous/missing data.\n",
    "   \n",
    "## Data Exploration\n",
    "\n",
    "First, let's take a look through our data to have an idea of what we're working with.\n",
    "\n",
    "**Can we identify any issues we might have in attempting to answer our motivating questions?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>shipment_id</th>\n",
       "      <th>shipment_mode</th>\n",
       "      <th>shipment_load_type</th>\n",
       "      <th>leg_mode_type</th>\n",
       "      <th>address_type</th>\n",
       "      <th>update_event_type</th>\n",
       "      <th>update_date_type</th>\n",
       "      <th>source</th>\n",
       "      <th>created_by</th>\n",
       "      <th>update_lead_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vu3226743587913466488858141657759283EITU9037961</td>\n",
       "      <td>879134</td>\n",
       "      <td>Ocean</td>\n",
       "      <td>LCL</td>\n",
       "      <td>Truck - Domestic</td>\n",
       "      <td>consolidation</td>\n",
       "      <td>departure</td>\n",
       "      <td>scheduled</td>\n",
       "      <td>human</td>\n",
       "      <td>Flora Zhu</td>\n",
       "      <td>631.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vu3226743487913466488858141657563713EITU9037961</td>\n",
       "      <td>879134</td>\n",
       "      <td>Ocean</td>\n",
       "      <td>LCL</td>\n",
       "      <td>Truck - Domestic</td>\n",
       "      <td>departure_port</td>\n",
       "      <td>arrival</td>\n",
       "      <td>scheduled</td>\n",
       "      <td>human</td>\n",
       "      <td>Flora Zhu</td>\n",
       "      <td>631.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vu3226743487793366488858141654563713EITU9037961</td>\n",
       "      <td>877933</td>\n",
       "      <td>Ocean</td>\n",
       "      <td>LCL</td>\n",
       "      <td>Truck - Domestic</td>\n",
       "      <td>departure_port</td>\n",
       "      <td>arrival</td>\n",
       "      <td>scheduled</td>\n",
       "      <td>human</td>\n",
       "      <td>Flora Zhu</td>\n",
       "      <td>631.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vu3226743587793366488858141654759283EITU9037961</td>\n",
       "      <td>877933</td>\n",
       "      <td>Ocean</td>\n",
       "      <td>LCL</td>\n",
       "      <td>Truck - Domestic</td>\n",
       "      <td>consolidation</td>\n",
       "      <td>departure</td>\n",
       "      <td>scheduled</td>\n",
       "      <td>human</td>\n",
       "      <td>Flora Zhu</td>\n",
       "      <td>631.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vu3226743587487766488858141651759283EITU9037961</td>\n",
       "      <td>874877</td>\n",
       "      <td>Ocean</td>\n",
       "      <td>LCL</td>\n",
       "      <td>Truck - Domestic</td>\n",
       "      <td>consolidation</td>\n",
       "      <td>departure</td>\n",
       "      <td>scheduled</td>\n",
       "      <td>human</td>\n",
       "      <td>Flora Zhu</td>\n",
       "      <td>631.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                id  shipment_id shipment_mode  \\\n",
       "0  vu3226743587913466488858141657759283EITU9037961       879134         Ocean   \n",
       "1  vu3226743487913466488858141657563713EITU9037961       879134         Ocean   \n",
       "2  vu3226743487793366488858141654563713EITU9037961       877933         Ocean   \n",
       "3  vu3226743587793366488858141654759283EITU9037961       877933         Ocean   \n",
       "4  vu3226743587487766488858141651759283EITU9037961       874877         Ocean   \n",
       "\n",
       "  shipment_load_type     leg_mode_type    address_type update_event_type  \\\n",
       "0                LCL  Truck - Domestic   consolidation         departure   \n",
       "1                LCL  Truck - Domestic  departure_port           arrival   \n",
       "2                LCL  Truck - Domestic  departure_port           arrival   \n",
       "3                LCL  Truck - Domestic   consolidation         departure   \n",
       "4                LCL  Truck - Domestic   consolidation         departure   \n",
       "\n",
       "  update_date_type source created_by  update_lead_hours  \n",
       "0        scheduled  human  Flora Zhu             631.00  \n",
       "1        scheduled  human  Flora Zhu             631.00  \n",
       "2        scheduled  human  Flora Zhu             631.00  \n",
       "3        scheduled  human  Flora Zhu             631.00  \n",
       "4        scheduled  human  Flora Zhu             631.00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question? Explore the data and determine some issues we may see with this analysis\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Percentage of Updates: Human vs. Automated\n",
    "\n",
    "I'm solving this by stringing together some logic to **only solve for air and ocean milestones** (that's all we want right now) and **choosing only actual dates, not scheduled**. \n",
    "\n",
    "From there we get a total count of rows, and final determine the count of each value in a series before dividing by the total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "human           0.65\n",
       "no user found   0.29\n",
       "cargosmart      0.03\n",
       "inttra          0.02\n",
       "crux            0.00\n",
       "Name: source, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One, less-readable way to filter data is to create a series that holds conditional expressions\n",
    "# for example\n",
    "ocean_filter = df.shipment_mode == 'Ocean'\n",
    "air_filter = df.shipment_mode == 'Air'\n",
    "milestones_filter = df.update_date_type == 'actual'\n",
    "final_filter =  (ocean_filter | air_filter ) & milestones_filter\n",
    "\n",
    "# We'll stop to discuss what these above filters mean here.\n",
    "total_rows = df[final_filter]['id'].count()\n",
    "df[final_filter]['source'].value_counts()/total_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Work Session\n",
    "\n",
    "After examining this solution work through your own solution utilizing another way to cut data. This could be solved using `iloc`, `loc`, or <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.query.html\">query which I suggest</a>. You can also use the <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html\">groupby function</a> to circumvent `value_counts`.\n",
    "\n",
    "Try to answer this question in the most Pythonic, efficient, or visually appealing way; for example, try answering this question with one line of code! Furthermore, think about how we could persist this result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Improvement in Update Speed for Automation\n",
    "\n",
    "Well, we learned by answering the prior question that the majority of our updates are coming from humans, with a bit of our updates provided by `crux` or `inttra` or `cargosmart`. Nearly 30% fell into the `no user found` category. If you dig a little bit deeper, you'll find that we also have some null values present in this column. \n",
    "\n",
    "In this next challenge, we're going to do a handful of things:\n",
    "    \n",
    "    1. Use a separate CSV \"user_types.csv\" which maps \"Human\" users to bots, individuals or groups\n",
    "    2. Using logic source and user type, determine if the the update was a bot, individual, or shared account\n",
    "    3. Drop null values\n",
    "    4. Eliminate outlier data and calculate average update speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this new data table which is updated using the filter we did in part 1.\n",
    "data = df[final_filter]\n",
    "\n",
    "#Retrieve user/type mapping\n",
    "# read csv in here\n",
    "\n",
    "# Create a new column with user_type in our current DF\n",
    "# combine this csv info with our current dataframe here\n",
    "\n",
    "# Drop rows where the created_by or source are null\n",
    "# drop rows here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for determining what type of user we have\n",
    "def get_user(row):\n",
    "    if row['source'] in ('crux', 'inttra', 'cargosmart'):\n",
    "        return 'bot'\n",
    "    if (row['source'] == 'no user found'):\n",
    "        return row['user_type']\n",
    "    if (row['source'] == 'human'):\n",
    "        return row['user_type']\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Use this function to create a new column from our logic in our dataframe\n",
    "# create column with function here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll then want to drop all null values from this column that we'll be using moving forward\n",
    "# drop NA values\n",
    "\n",
    "# Now let's take a look at what we're working with\n",
    "#data['update_lead_hours'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pause for Deep Dive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorization\n",
    "The `.apply` method is less verbose than writing a big loop, but it's still doing a loop under the hood. How can we make this faster?\n",
    "\n",
    "Pandas is based on numpy, which has the concept of \"vectorized\" operations. These are functions that operate on an entire vector and are optimized at the C level. I don't know a whole lot about computers. It's still doing a loop _somewhere_ in there, but it's all happening at a lower level of code.\n",
    "\n",
    "Think about something like adding two columns together - I _could_ implement this as a loop or an apply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a   b   c\n",
       "0  0  10  10\n",
       "1  1  11  12\n",
       "2  2  12  14\n",
       "3  3  13  16\n",
       "4  4  14  18\n",
       "5  5  15  20\n",
       "6  6  16  22\n",
       "7  7  17  24\n",
       "8  8  18  26\n",
       "9  9  19  28"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.DataFrame(zip(range(0, 10), range(10 ,20)), columns=['a', 'b'])\n",
    "\n",
    "def addition(a: int, b: int) -> int:\n",
    "    \"\"\"add two numbers together\"\"\"\n",
    "    return a + b\n",
    "\n",
    "test_data['c'] = test_data.apply(lambda x: addition(x.a, x.b), axis=1)\n",
    "test_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but, that's pretty silly. Normally, we would just use the built in addition operator for pandas and just add the columns together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>c2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a   b   c  c2\n",
       "0  0  10  10  10\n",
       "1  1  11  12  12\n",
       "2  2  12  14  14\n",
       "3  3  13  16  16\n",
       "4  4  14  18  18\n",
       "5  5  15  20  20\n",
       "6  6  16  22  22\n",
       "7  7  17  24  24\n",
       "8  8  18  26  26\n",
       "9  9  19  28  28"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['c2'] = test_data.a + test_data.b\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, before we resort to using `.apply`, we should ask ourselves: **is there a built-in pandas or numpy function that can accomplish what I want?**\n",
    "\n",
    "In the above example, we want to create an additional column by applying some conditional logic to the `source` column. This is a good fit for the `np.where` function, which takes three arguments:\n",
    "1. A boolean vector\n",
    "2. A vector or scalar representing the desired value if the above boolean is true\n",
    "3. A vector or scalar representing the desired value if the above boolean is false\n",
    "\n",
    "Since we have multiple conditions, we'll have to nest multiple `np.where`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['categorical_user_type_2'] = np.where(\n",
    "    data.source.isin(['crux', 'inttra', 'cargosmart']), 'bot',\n",
    "    np.where(\n",
    "        data.source.isin(['no user found', 'human']), data.user_type, np.nan))\n",
    "        \n",
    "(data.categorical_user_type == data.categorical_user_type_2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "start = time()\n",
    "data['categorical_user_type'] = data.apply(get_user, axis=1)\n",
    "apply_seconds = time() - start\n",
    "\n",
    "start = time()\n",
    "data['categorical_user_type_2'] = np.where(\n",
    "    data.source.isin(['crux', 'inttra', 'cargosmart']), 'bot',\n",
    "    np.where(\n",
    "        data.source.isin(['no user found', 'human']), data.user_type, np.nan))\n",
    "vectorized_seconds = time() - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply took:      12.2s\n",
      "Vectorized took: 0.1s\n"
     ]
    }
   ],
   "source": [
    "print('Apply took:      {:,.1f}s'.format(apply_seconds))\n",
    "print('Vectorized took: {:,.1f}s'.format(vectorized_seconds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Outliers\n",
    "\n",
    "We see that the long-tail of update lead hours is very long. On average, our milestone updates are logged $313$ hours after occuring, with the median sitting at $20$ hours. For this analysis we can probably assume no \"actual\" updates should be happening before the fact, so we'll drop all values greater than $0$. \n",
    "\n",
    "It seems like some of our large outliers are significantly skewing our data. I think 2 weeks is a reasonable assumption to make for the most amount of time it should take to update a milestone -- we'll drop all rows with lead hours over $336$ hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237193"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset = data[(data['update_lead_hours'] < 0) & (data['update_lead_hours'] > -336.0)]\n",
    "\n",
    "# our final dataset has significantly less values\n",
    "final_dataset['id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "categorical_user_type\n",
       "bot           -6.11\n",
       "individual   -72.75\n",
       "shared       -24.77\n",
       "Name: update_lead_hours, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataset.groupby(by='categorical_user_type')['update_lead_hours'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution\n",
    "\n",
    "This gives us the expected solution! Bots are significantly faster than human users, and accounts run by individuals are slower at making updates than those owned by shared accounts (teams).\n",
    "\n",
    "### Group Work\n",
    "\n",
    "We've walked through a single method for arriving at this solution. \n",
    "**Can you arrive at this solution through another method? Is there any other relevant measures we could calculate to provide more insight?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
