{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis in Pandas with Functions\n",
    "\n",
    "How can we write clean code to organize messy analytical work?\n",
    "\n",
    "Objectives:\n",
    "1. Show how to break down a broad business problem into answerable data questions\n",
    "2. Answer these questions in a diligent, clear, and reproducible way\n",
    "3. Drive further exploration based on the answers to these questions\n",
    "\n",
    "Number (2) above is where clean, effective Python code will save your ass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Business Problem: CRD Changes\n",
    "\n",
    "An example of how a business partner might approach this, via **email**, **slack**, or **intake meeting**:\n",
    "\n",
    "> We're facing a lot of uncertainty due to changing CRDs - it's difficult or impossible to arrange origin trucking, and some of our sailing/filght assignments are being invalidated. Can we get more visibility into how often this is happening? \n",
    "\n",
    "It pays to follow up with the stakeholder here to get some context and figure out how to best approach the problem:\n",
    "1. What's the specific business risk involved? The first example above outlines this fairly well.\n",
    "2. What are the specific scenarios where we might care about this?\n",
    "3. How can this information be _actionable_ for the end user?\n",
    "\n",
    "Number (3) is especially important here - ultimately, whatever solution that you provide, it should speak to some action that the stakeholder team can take based on the data.\n",
    "\n",
    "Let's say you ask for clarification and get the following additional information:\n",
    "\n",
    "> We're specifically interested in ocean shipments, because anecdotally it's really disrupting our fullillment process. If a CRD changes and we can't use the original assignment, then we might end up with dead inventory which has a pretty direct financial impact. It also creates a bad experience for the client, who may end up with a longer transit time.\n",
    "\n",
    "> If we knew how often CRDs were historically changing, we could get a sense of how much this is contributing to our overall fulfillment problems. We can start to \"score\" clients based on the likelihood that their CRDs will change, and either enforce better behavior or account for this in our fulfillment process. It would be really cool to actually _anticipate_ which CRDs will change and by how much, anecdotally this seems really unpredictable.\n",
    "\n",
    "## Framing Analytical Questions\n",
    "\n",
    "Great - now we have a better understanding of how the business is thinking about this problem. But where do we even start with actually pulling data?\n",
    "\n",
    "While some of the suggestions from our stakeholder might be exciting - predicting CRD changes, scoring clients - here it pays to ***challenge your assumptions, start as simple as possible, and increase complexity in a logical and incremental fashion***\n",
    "\n",
    "We can start by laying out some clearly defined questions that we should be able to answer with data:\n",
    "- How often do shipment CRDs change?\n",
    "- When CRD does change, how much on average does it differ from the original or previous CRD?\n",
    "- When do CRD changes typically occur, relative to quoting and relative to the CRD itself?\n",
    "\n",
    "All of these should give us insight into the more general questions asked by our stakeholder (how much of a problem is this?) while also giving us a sense of how much further we can take this analysis. All of these questions can also be sliced on different dimensions, like client segment and trade-lane, to get more insight (if it's actionable).\n",
    "\n",
    "***What data points would we need to answer these basic questions?***\n",
    "- Each instance of a CRD being created or changed for a shipment\n",
    "- The time that the creation/change took place\n",
    "- The CRD at that time\n",
    "- When the shipment was quoted\n",
    "\n",
    "Unfortunately we don't have a true event-based data table for CRDs (if this has changed, awesome). But we _can_ back out the changes from the audits table. Let's grab the data and get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "\n",
    "# plotting\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams[\"figure.figsize\"] = (11,6)\n",
    "%config IPCompleter.greedy=True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing internal packages\n",
    "We'll want to use our internal Python library to access Snowflake. It's easy to install!\n",
    "\n",
    "Check out [PyPi instructions here](https://github.flexport.io/flexport/kimono/tree/master/astronomer/commonlib#step-6-installing-your-package) and navigate the [PyPi server here](http://10.70.168.13:6543/#/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip3 install -i http://10.70.168.13:6543/simple/ analytics-utils==1.1.4 --trusted-host 10.70.168.13\n",
    "from analytics_utils.utils import snowflake as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with a query\n",
    "\n",
    "The data has to come from somewhere...\n",
    "\n",
    "Some general notes on SQL queries as part of EDA workflow:\n",
    "- Code structure\n",
    "    - You can extract the query into a separate file, but I like keeping it in the notebook so things are self contained and easier to reference\n",
    "    - I like defining the query as a standalone string that you can reference in a function. That way, you can edit the query separately from running it\n",
    "- How to write the query\n",
    "    - Avoid including too much complex logic/transformation in the query itself. Python code is generally easier to parse and understand what's going on (maybe just my opinion)\n",
    "    - We also want to avoid having to re-run the query a million times\n",
    "    - \"Go wide\" and include any data that you think you might need\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here I define my query as a string\n",
    "\n",
    "CRD_CHANGE_QUERY = (\n",
    "    \"\"\"\n",
    "    SELECT \n",
    "      a.id as audit_id,\n",
    "      a.auditable_id as leg_id,\n",
    "      a.action,\n",
    "      sl.shipment_id,\n",
    "      a.created_at as changed_at,\n",
    "      CASE WHEN ARRAY_SIZE(a.audited_changes:cargo_ready_date) = 2\n",
    "        THEN a.audited_changes:cargo_ready_date[1]\n",
    "        ELSE a.audited_changes:cargo_ready_date END as crd,\n",
    "      q.quote_submitted_at,\n",
    "      q.quote_accepted_at\n",
    "    FROM core.audits as a\n",
    "       JOIN legacy.bi_shipment_legs as sl\n",
    "       ON (a.auditable_id = sl.leg_id \n",
    "           AND a.auditable_type in ('OperationalRoute::Leg', 'Leg')\n",
    "           AND sl.from_origin_address)\n",
    "       JOIN legacy.prep_quotes as q\n",
    "       ON (sl.shipment_id = q.shipment_id and q.quote_accepted_at is not null)\n",
    "    WHERE\n",
    "      a.audited_changes:cargo_ready_date is not null\n",
    "      AND a.audited_changes:cargo_ready_date != 'null'\n",
    "      AND a.created_at BETWEEN '{start}' and '{end}'\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "# notice the bits in curly braces - these are arguments that we will later *interpolate* into the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, I want to define a function to run a query with arguments\n",
    "#  using a function here isolates the code necessary to pull data, so it's super easy to call later on\n",
    "\n",
    "# first, let's set up a blank function\n",
    "#  there's a lot of stuff here, but it doesn't actually do anything\n",
    "def get_crd_changes(start: date, end: date) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return every instance of a CRD changing during the period between ``start`` and ``end``\n",
    "    Pulling from the audits table\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anatomy of a function\n",
    "\n",
    "1. Name: make it descriptive, even if it's verbose\n",
    "2. Arguments: act as variables within the function. Here, we can put key pieces of configuration that we might want to change\n",
    "    - Example: adding start and end dates to our query. Instead of changing the query itself, we can define arguments that are *interpolated* into the query text\n",
    "3. Return something - in this case, a DataFrame\n",
    "    - In the above example, we used `pass` to return nothing. This is very useful to skeleton out functions before you actually write them\n",
    "\n",
    "#### A note on type hints\n",
    "You may notice the **type hints** above. This is a new feature in Python 3 that allows us to specify input and output types. Each argument has a type, indicated with `:`, while the type of the data returned by the function is indicated outside of the function with `->`\n",
    "\n",
    "Type hints are not required, nor are they enforced. There are, however, tools like [MyPy](http://mypy-lang.org/) that can be used to check code against type hints, and these are a good option for production code.\n",
    "\n",
    "<a href=\"https://imgflip.com/i/4wtzfz\"><img src=\"https://i.imgflip.com/4wtzfz.jpg\" title=\"made at imgflip.com\"/></a>\n",
    "\n",
    "Check it out below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to add two... things of unspecified type\n",
    "def my_function(a, b):\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What will this return?\n",
    "#my_function(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What will this return?\n",
    "#my_function('a', 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What will this return?\n",
    "#my_function('a', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's rewrite this with type hints\n",
    "def my_function_with_hints(a: int, b: int) -> int:\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# However, does this actually do anything?\n",
    "#my_function_with_hints('a', 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why bother with type hints anyway?\n",
    "\n",
    "Type hints act as *rich documentation* of a function's intended usage. If you're collaborating with someone, or revisiting old code, you can quickly understand what to expect. Sure, it's not enforced, but it is helpful.\n",
    "\n",
    "We most often see type hints in *production-level code*, where style guidelines may require their usage. So, is there any value in using them for ad-hoc analysis in notebooks, or is this just Tyler being a hardass (who has written production code)?\n",
    "\n",
    "My *opinion* is emphatically yes! For all the reasons above, using type hints helps us write clean, well documented code without much additional effort. It also forces us to write functions with clear usage and avoid any unpleasant type flexibility that may be allowed by Python.\n",
    "\n",
    "#### A note on *docstrings*\n",
    "\n",
    "After the function definitions, you can include documentation using triple quotes. This is referred to as a \"docstring\" and acts as another key piece of documentation around functions. Again, these are typically required as part of style guidelines for production code - but, they can be useful for analytical work as well.\n",
    "\n",
    "What should the docstring contain?\n",
    "- A *concise* explanation of what the function does. If you can't concisely explain, it's likely that the function is doing too much!\n",
    "- Explanation for how each of the arguments of a function are used \n",
    "- Explanation for the data returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time to actually write the function\n",
    "def get_crd_changes(start: date, end: date) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return every instance of a CRD changing during the period between ``start`` and ``end``\n",
    "    Pulling from the audits table\n",
    "    \"\"\"\n",
    "    # interpolate arguments into the query\n",
    "    formatted_query = CRD_CHANGE_QUERY.format(start=start, end=end)\n",
    "    \n",
    "    # use our snowflake package to run the query\n",
    "    return sf.run_snowflake_query(formatted_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `.format()` \"just works\" with dates, but let's make sure...\n",
    "'{start}'.format(start=date(2020,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use our function\n",
    "# our use of arguments comes in handy here\n",
    "#   we can run with a shorter date range to confirm that this is working\n",
    "#   without waiting forever\n",
    "crd_changes = get_crd_changes(date(2020, 1, 1), date(2020, 1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity checking the data\n",
    "\n",
    "Prior to making any assertions, let's make sure that things look OK from a high level\n",
    "\n",
    "- Is the _grain_ what I expected? \n",
    "    - It's a good practice to include some kind of primary key in your query, just so this is easier to reason about\n",
    "    - the `.value_counts()` method is a lifesaver here\n",
    "- Do columns take on the values that I expected?\n",
    "    - Is anything missing more often than I would expect?\n",
    "- Is the size in line with what I would expect (orders of magnitude)\n",
    "- Other specific pieces of logic that might make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the grain correct?\n",
    "crd_changes.audit_id.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does everything look as expected?\n",
    "crd_changes.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are the types correct?\n",
    "crd_changes.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is anything missing more often than we expect?\n",
    "pd.isnull(crd_changes).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how much data was returned?\n",
    "crd_changes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how does this compare to the number of shipments?\n",
    "crd_changes.shipment_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to fix the formatting of the `crd` column\n",
    "#pd.to_datetime(crd_changes.crd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we ran into errors parsing CRD into date type... how many rows are affected?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another useful application for functions: isolating and compartmentalizing code\n",
    "After sanity checking the data above, we found one thing we wanted to change - the formatting around the CRD column. We *could* go make that change in the query, which may or may not be cumbersome. To some extent it's up to you.\n",
    "\n",
    "One disadvantage of putting *all* logic in the query (as mentioned above), is that this requires you to re-run the query any time you tweak the logic, which may slow down your iteration.\n",
    "\n",
    "However, if you put this transformation in Python, you run into potential cell state issues. If I alter the `crd` column in place, that might cause problems if I run the cells out of order, and it becomes hard for me to keep track of the state of individual objects.\n",
    "\n",
    "In these cases I like to write an additional function to isolate all code used to transform the data in Python. In this function, you could include:\n",
    "- date and string formatting that is cumbersome in SQL\n",
    "- aggregation and window functions that are possible, but cumbersome and difficult to read in SQL\n",
    "- anything that you want to make configurable after the SQL query is run\n",
    "\n",
    "This way, you can keep the execution of all data processing in two functions, and focus on the analysis below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_change_data(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    perform post-processing on the query output from ``get_crd_changes``\n",
    "    - strip double quotes from CRD\n",
    "    \"\"\"\n",
    "    output = data.copy()\n",
    "    output['crd'] = pd.to_datetime(crd_changes.crd.str.strip('\"'), errors='coerce')\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crd_formatted = format_change_data(crd_changes)\n",
    "crd_formatted.crd.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start actually answering our questions\n",
    "\n",
    "First, ***how often do shipment CRDs change?***\n",
    "\n",
    "Now that we know the data is formatted properly, let's go back and get a bigger sample\n",
    "\n",
    "Then, let's think of ways to summarize this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what percentage of legs have more than one CRD? \n",
    "leg_crd_counts = crd_changes.groupby('leg_id')['audit_id'].count()\n",
    "(leg_crd_counts > 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how often do CRDs change more than once?\n",
    "leg_crd_counts.loc[leg_crd_counts > 1].hist(bins=np.arange(2, 10, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(leg_crd_counts.value_counts() / len(leg_crd_counts)).head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When CRD does change, how much on average does it differ from the original or previous CRD?**\n",
    "\n",
    "We'll need to do some additional transformation:\n",
    "- We'll need to add \"first CRD\" as a column\n",
    "- We'll need to add \"previous CRD\" as a column\n",
    "\n",
    "Let's walk through these transformations, then build a function to do this for us\n",
    "\n",
    "**Blank function below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_change_data_updated(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    format columns from ``get_crd_changes``\n",
    "    add columns for previous/first CRD, as well as differences\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's come up with the answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My solution below\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "This space left intentionally blank\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's add this logic to our processing function\n",
    "# normally I wouldn't write a second function - I'd just update the first one\n",
    "def format_change_data_updated(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    perform post-processing on the query output from ``get_crd_changes``\n",
    "    - strip double quotes from CRD\n",
    "    - add first CRD information\n",
    "    - add previous CRD information\n",
    "    \"\"\"\n",
    "    # crd formatting\n",
    "    output = data.copy()\n",
    "    output['crd'] = pd.to_datetime(crd_changes.crd.str.strip('\"'), errors='coerce')\n",
    "    \n",
    "    # add first and previous CRD information\n",
    "    first_crd = output.sort_values('changed_at').groupby('leg_id')[['crd', 'changed_at']].first()\n",
    "    previous_crd = output.sort_values('changed_at').groupby('leg_id').crd.shift(1)\n",
    "    \n",
    "    output = output \\\n",
    "        .join(previous_crd, how='inner', rsuffix='_prev') \\\n",
    "        .set_index('leg_id') \\\n",
    "        .join(first_crd, how='inner', rsuffix='_first') \\\n",
    "        .reset_index()\n",
    "    \n",
    "    output['crd_order'] = output.groupby('leg_id').changed_at.rank(method='min')\n",
    "    \n",
    "    # generate columns for differences\n",
    "    output['difference_from_prev'] = (output.crd - output.crd_prev) / np.timedelta64(1, 'D')\n",
    "    output['difference_from_first'] = (output.crd - output.crd_first) / np.timedelta64(1, 'D')\n",
    "    \n",
    "    # null the difference from first if it is the first\n",
    "    output.loc[output.crd_order == 1, 'difference_from_first'] = np.nan\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crd_comparison = format_change_data_updated(crd_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crd_comparison.difference_from_first.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crd_comparison.difference_from_first.hist(bins=np.arange(-20, 50, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crd_comparison.groupby('crd_order').agg(dict(leg_id='count', difference_from_first='mean')).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crd_comparison.groupby('crd_order').difference_from_first.quantile([0.25, 0.5, 0.75]).unstack().iloc[:10].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
